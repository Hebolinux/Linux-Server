# 1.0 开篇

计算机的结构由三部分组成，数据结构（软件）、操作系统、计算机组成（硬件），而各个计算机之间又可以通过计算机网络实现信息的互联互通，计算机组成这门课程要研究的就是计算机硬件在底层是如何相互协调工作的

在主机的内部，例如CPU、内存、硬盘，这些硬件上一定会存在金属针脚，这些金属针脚被用于传输数据；计算机本身被用于存储、计算数据，在计算机上的所有数据都以0或1的二进制方式存在并被识别，而0或1在硬件层面又通过低电平或高电平进行表示

计算机硬件识别二进制数据的原理实际是通过硬件上的金属针脚，每一个针脚能够识别一个电信号，通过电信号的低/高电平，将不同的电信号转化为对应的二进制数据，硬件上的金属针脚越多，能同时进行传输的电信号就越多，每一个针脚都是硬件用来收/发二进制数据的一个通道

计算机的主板除了能够安装各个硬件组件外，它的本质更是一个印刷电路板，在主板上能够看到很多"线"，这些"线"就是电路，其本质是为了导电，最终各个硬件的针脚都会通过这些电路连接，各个硬件之间传输二进制数据时，实际上就是向外发送低/高电平，通过多条电路可以传递多个二进制数位，每个二进制数据称为1bit

## 1.1 计算机的发展

本节以计算机系统概述为主要内容，计算机系统概述首先需要了解什么是计算机系统

### 什么是计算机系统

计算机系统由硬件和软件组成，硬件主要代表计算机的实体部分，如主机、外设等，软件是看得见、摸不着的东西，它由各类特殊功能的程序组成；硬件是计算机系统的物理基础，它决定了计算机系统的瓶颈，而软件则决定了能够将硬件的性能发挥到何种程度。所以评价一个计算机系统的好坏，却决于软、硬功能的总和

软件部分又能够划分为*系统软件*和*应用软件*，系统软件用于管理整个计算机系统，操作系统就是最典型的系统软件，还有例如DBMS（数据库管理系统）、标准程序库、网络软件、语言处理程序、服务程序等诸如此类都是系统软件。除了系统程序以外，用户日常接触最多的还是诸如迅雷、QQ等应用软件，应用软件指的是按任务需求编制成的各种程序

### 硬件的发展

1946年第一台电子数字计算机诞生：ENIAC，这台计算机采用了**电子管**作为它的逻辑元件，在开篇中有提过，计算机进行逻辑运算的时候，本质上就是处理电信号，而**逻辑单元指的就是用来处理电信号的最小的基本单元**，这样一台计算机实际上就是用电路连接非常多的逻辑单元，从而实现用电路来运算的功能。ENIAC共使用1.8万个电子管组成，由于电子管的物理特性，注定了ENIAC的占地面积高达170平方米、耗电量150千瓦，每秒5000次算数运算

[![逻辑元件发展史](https://s1.ax1x.com/2022/11/16/zePd2R.png)](https://imgse.com/i/zePd2R)

以ENIAC为代表的第一代计算机被称为*电子管时代*，原因是第一代计算机都使用电子管作为逻辑元件，造成计算机体积大、耗电量高、计算速度慢，在这一时期，程序员都是使用机器语言、通过纸带机打孔进行编程，极为不便

后来著名的贝尔实验室发明了晶体管，晶体管的电器特性能够替代电子管，且晶体管的体积要比电子管的体积小很多，所以用晶体管替换电子管作为计算机的逻辑元件，可以大幅度降低计算机的体积、耗电量，并通过晶体管体积较小的特性，可以设计更复杂的电路，使计算机的运算速度也更快。由此，第二代计算机也被称为*晶体管时代*，为了使计算机能够有自我管理的功能，这个时期也产生了操作系统雏形和更高级的语言，例如fortran

在晶体管时代，制造一台计算机大概需要几万到几十万个晶体管，需要将这些晶体管用手工的方式焊接到电路板上，所以这个阶段的硬件还是十分不可靠的。所以，诞生了集成电路，集成电路的诞生意味着计算机进入第三代：*中小规模集成电路时代*。这个时期，逻辑元件集成在电路板的基片上，集成电路的制造工艺意味着计算机的体积越来越小、功耗更低，同时集成电路要比晶体管手动焊接的可靠性更高。在这一阶段产生了更多的高级语言和分时操作系统，但计算机仍主要用于科学计算等专业用途

随着集成电路工艺的不断提升，慢慢进入了第四代：*大规模、超大规模集成电路时代*，此时开始出现微处理器、微型计算机，同时这个时期也开始诞生操作系统：Windows、Linux、MacOS

[![微处理器发展史](https://s1.ax1x.com/2022/11/16/zePaG9.png)](https://imgse.com/i/zePaG9)

这张表给出了Intel早期推出的CPU型号，其中**机器字长表示计算机一次整数运算能处理的二进制位数**，例如最早的8080型号的CPU一次只能处理8个二进制位，如果要用8080进行16个二进制位的加法，那么CPU必须进行两次整数运算，所以机器字长的提升会直接提升CPU的计算速度

- 1947年，贝尔实验室发明“晶体管”
- 1955年，原贝尔实验室成员 肖克利（晶体管之父）在硅谷创建 肖克利实验室股份有限公司
- 1957年，八叛徒（traitorous eight）创立 仙童半导体公司
- 1959年，仙童半导体公司发明“集成电路”
- 1968年，摩尔等3人离开仙童，创立Intel
- 1969年，桑德斯离开仙童，创立AMD

摩尔定律：集成电路上可容纳的晶体管数目，约每隔18个月会增加一倍，整体性能也将提升一倍。摩尔定律揭示了信息技术进步的速度

### 软件的发展

软件的发展需要从编程语言开始了解，所有的软件都是由编程语言编写，所以编程语言的发展直接就决定的软件世界的丰富程度。在计算机发展的初期，所有的编程都需要使用机器语言编写，由于机器语言的可读性差而产生了汇编语言，两者的本质基本一样，只不过汇编语言会将机器语言转换成更方便人记忆的符号

早期程序员进行编程时，除了需要关注要解决的问题是什么之外，还需要关注使用的机器特性能识别什么语言，因此在这个阶段程序员编程是非常困难的，也注定了这个阶段不会有丰富的软件世界。后来，为了使编程更加方便，就产生了一些高级语言，例如PASCAL、C++等，程序员再使用高级语言编程时，就不再需要考虑机器的具体特性，而只需要关注需要解决的问题

有了高级语言作为基础，软件世界也越来越丰富，随着计算机网络技术的发展，又出现了类似Java、Python等更适用于网络环境的语言。总之，编程语言就是用于制造软件的，编程语言是否好用、是否方便直接决定了软件世界是否丰富

除了应用软件的发展之外，也有操作系统的系统软件的发展，早期的操作系统，例如DOS系统只能通过命令行来操作计算机，后来逐渐出现了图形化的操作界面，例如Windows、Android、iOS等

### 目前的发展趋势

目前来看，计算机的发展有“两级分化”的趋势，一种是微型计算机向更微型化、网络化、高性能、多用途方向发展，例如智能穿戴设备、手机等，另一种是巨型机向更巨型化、超高速、并行处理、智能化方向发展，例如国家目前最快的超级计算机 神威·太湖之光

[超级计算机世界排行](https://www.top500.org/)

## 1.2 计算机系统层次结构

### 1.2.1 计算机硬件的基本组成

计算机硬件的基本组成分为两种结构，*早期的冯诺依曼机结构*和*现代计算机的结构*，现代计算机结构也是对冯诺依曼结构的优化

#### 冯诺依曼机结构

世界上第一台计算机ENIAC，是通过程序员手动接线来控制计算的，也就意味着计算机要执行的任何一个操作都需要程序员人工手动调整。后来，冯·诺依曼提出**“存储程序”**的概念，**将指令以二进制代码的形式事先输入计算机的主存储器**，然后按照存储器中的首地址执行程序的第一条指令，以后就按该程序的规定顺序执行其他指令，直到程序执行结束。第一台采用冯·诺依曼结构的计算机是EDVAC，同时冯·诺依曼也是ENIAC的设计顾问

[![冯·诺依曼机](https://s1.ax1x.com/2022/11/16/zePUPJ.png)](https://imgse.com/i/zePUPJ)

对于冯·诺依曼计算机结构的解析：计算机本身就是用来处理数据的，所以首先必须要有一个**输入设备**，来将数据输入计算机中，这里的数据包括要进行数学运算的数据或程序（也就是指令集合），输入设备的作用就是*将信息转换为机器能识别的形式，也就是二进制数据*；数据通过输入设备处理后，先流向了**运算器**，通过运算器的中转才会将数据存放到**存储器**中，所以存储器的作用就是*存放数据和程序*、运算器最主要的功能是*实现算数运算和逻辑运算*，经过运算器的处理后，数据的运算结果会通过输出设备*转换成人熟悉的形式*

那么还有一个非常重要的组件 **控制器**，控制器会通过电信号来协调其他部件相互配合工作，控制器也会负责解析存储器内存放的程序指令，图中可以看到有一条*数据线*从存储器指向控制器，这条线表示控制器从存储器中读取出一条指令的数据流，以算数运算为例，控制器从存储器中读取到一条加法指令后，才会指挥运算器执行相应的加法运算，因此控制器的作用就是**指挥程序运行**

在以上冯·诺依曼计算机结构图中，数据或程序指的就是软件，其他部分都是硬件部件。**在计算机系统中，软件和硬件在逻辑上是等效的**，意思是对于同一个功能，既可以用软件来实现，也可以用硬件来实现，但相对的，通过软件实现功能成本更低、效率也更低，硬件实现功能成本更高、效率也更高。例如，对于乘法运算，可以在运算器里面设计一个专门的硬件电路实现乘法运算，只需要一条乘法指令，运算器就可以得到最终的运算结果，没有这个硬件时，也可以通过软件的方式，执行多次加法运算实现，因为乘法也可以通过多次的加法运算来模拟

冯·诺依曼计算机的特点：

1. 计算机由五大部分组成
2. 指令和数据以同等地位存储于存储器，可根据存储单元的地址执行寻访操作
3. 指令和数据都使用二进制表示
4. 指令由操作码和地址码组成
5. 存储程序
6. **以运算器为中心**

操作码表明了该指令要进行什么操作，例如加、减运算操作；地址码表明了要进行操作的数据存放在存储器的什么地址，程序执行的过程中，实际上就是根据程序中指明的地址码，对特定的存储单元执行寻访操作

冯·诺依曼结构中，运算器处于整个结构的中心位置，无论输入、输出都需要通过运算器，存放到存储器当中的数据也需要先通过运算器中转，这意味着数据的传送必须多次经过运算器，运算器的主要工作是处理数据，多次参与数据的中转操作会导致运算器的工作效率降低

#### 现代计算机结构

[![现代计算机结构](https://s1.ax1x.com/2022/11/16/zePYaF.png)](https://imgse.com/i/zePYaF)

现代计算机结构就是针对冯·诺依曼机结构做出的优化，传统的冯·诺依曼机结构以运算器为中心，导致运算器的效率降低，现代计算机结构以**存储器为中心**，输入、输出设备都是直接将数据或程序存储到存储器中，通过运算器的运算后将计算机过取出，这样可以更多的解放运算器的时间，提高运算器的工作效率

由于运算器和控制器的逻辑关系十分紧密，在大规模集成电路制作工艺出现后，这两个部件通常是被集成在同一个芯片上的，整合了这两个部件的硬件就是CPU

[![现代计算机结构简化](https://s1.ax1x.com/2022/11/16/zePt54.png)](https://imgse.com/i/zePt54)

现代计算机结构简化后如图，CPU内包含了运算器和控制器，控制器通过控制线*控制运算器的下一步操作指令*、*控制主存储器的读写*、*控制I/O设备的启停*；主存储器和CPU之间进行数据交换，需要参与运算的数据交给运算器，指令数据则交给控制器，由控制器解析指令的含义；I/O设备会直接和主存储器进行数据交换

### 1.2.2 各个硬件的工作原理

#### 主存储器的基本组成

[![主存储器的基本组成](https://s1.ax1x.com/2022/11/16/zeeb2F.png)](https://imgse.com/i/zeeb2F)

主存储器里用于存放数据的单位是**存储体**，存储体由一系列存储元件构成，可用于存放二进制数据，除了存储体之外还有两个重要的寄存器：**MAR（Memory Address Register 存储地址寄存器）**和**MDR（Memory Data Register 存储数据寄存器）**，寄存器本身也是用于存放二进制数据的，只不过MAR与MDR存储的数据各不相同

主存储器中的数据都存放在存储体中，当CPU要从主存储器中取出一个数据时，CPU会将该数据在主存储器中的存放地址写入MAR中，主存储器通过读取MAR中的存放地址，在存储体中找到对应的数据，并将该数据写入MDR中，最后CPU通过数据线路从MDR中取出数据

当CPU要在主存储器中写入数据时，CPU会在MAR中写入要将数据存储到主存储器的某个具体地址，然后将要写入的数据本身写入MDR，再通过控制总线告诉主存储器本次操作是写入操作，主存储器根据CPU提供的这三个信息就能够往存储体中写入数据

##### 存储体

在了解完MAR和MDR的作用后，再看存储体的构成，**数据在存储体内按地址存储**；整个存储体会被划分为多个**存储单元**，每一个存储单元里会存放一串二进制代码，而这一串二进制代码的组合也被称为一个**存储字（word）**，一个存储单元中能够存储的二进制代码的位数也被称为**存储字长**，通常每个存储单元中能够存放的二进制位数都是8bit或8bit的整数倍，例如16bit、32bit、64bit等

**每一个存储单元会对应一个地址信息**，地址信息从0开始计算，这里的地址信息也就是在MAR内要写入的地址信息，例如，CPU要读取2号存储单元内的数据，那么MAR内就应该写入2这个地址；一方面，MAR里写入的数据表示存储单元所对应的地址信息，那么MAR本身的二进制位数就能够直接反映出存储体中有多少个存储单元，另一方面，从存储单元中取出的数据会存放到MDR中，所以MDR的位数就等同于存储字长，例如，MAR的位数等于4时，存储体中总共有2^4个存储单元，MDR的位数等于16时，每个存储单元可存放16bit，一个字也等于16bit。*需要注意的是，存储字word并不等于常见的存储单位字节Byte，两者较为容易混淆*

存储元：存储二进制的电子元件，每个存储元件可存1bit，多个存储元配合电路就组成了一个存储单元

#### 运算器的基本组成

[![运算器的基本组成](https://s1.ax1x.com/2022/11/17/zmghxx.png)](https://imgse.com/i/zmghxx)

运算器的作用就是用于实现算术运算和逻辑运算，其中，**ACC**也是一个寄存器，英文全称翻译为中文也叫做累加器，ACC用于存放酸钠书运算中的操作数或运算结果；**MQ**乘商寄存器，这个寄存器只会在执行乘法或除法运算时，才会存放操作数或操作结果；**X**也叫做通用寄存器，通用寄存器一般在运算器里可能会有多个，理论上只要有一个通用寄存器就能够实现算术运算；**ALU**是运算器的核心部件，ALU内集成了复杂的电路，通过这些电路实现算数运算和逻辑运算。前面所提到的三个寄存器就是用于存放一些数据的，其本身硬件构造并不复杂，运算器里边制造成本最高的就是ALU

#### 控制器的基本组成

[![控制器的基本组成](https://s1.ax1x.com/2022/11/17/zmRSpR.png)](https://imgse.com/i/zmRSpR)

**CU**控制单元是控制器最核心的部件，其本身也集成了非常复杂的电路，可以完成分析指令，并且能够给其他部件发出控制信号；计算机最主要的工作就是执行代码，而代码本质上也就是一条条的指令，那么每完成一条指令就需要分为3个阶段：

1. 取指令 -- PC
2. 分析指令 -- IR
3. 执行指令 -- CU

取指令会根据**PC**程序计数器里面所记录的指令地址，从主存储器中取出指令，取出的指令会被存放在**IR**指令寄存器当中，由**CU**来分析该指令要实现的操作，执行分析完成后，由CU控制其他部件配合完成指令的具体执行；这是完成一条指令的3个阶段，其中取指令和分析指令又被统称为*取指*

#### 计算机的工作过程

[![计算机工作流程01](https://s1.ax1x.com/2022/11/22/zlWDot.png)](https://imgse.com/i/zlWDot)

以一段C语言代码为例，查看计算机的工作过程。对于计算机而言，它无法直接处理高级语言，高级语言经过编译后会翻译成计算机能读懂的机器语言，同时会将这段程序装入主存，在主存中的存储方式如图右侧所示。图中每一个*主存地址*就对应的存储单元的地址，也就是说每一个主存地址都代表一个存储单元，在C语言代码中定义了4个变量a、b、c、y，其中a变量的值存储在5号存储单元，将5号主存地址的指令框内的二进制转化为十进制就是a变量的值2，其他三个变量依次类推

除了主存地址5\~8用于存储变量值以外，0\~4号地址被用于存储C语言中`y=a*b+c`这段程序所对应的机器指令。在这个图示中，每一个存储单元都是16bit的存储字长，每一条指令的字长也是16bit，只不过执行指令时，CPU会自动将指令拆解为操作码和地址码

[![计算机工作流程02](https://s1.ax1x.com/2022/11/22/z1uXJe.png)](https://imgse.com/i/z1uXJe)

在这个示例中，I/O设备不重要，运算器和控制器集成在CPU中，右侧图中所有的指令和数据都存放在存储体中，这段C语言程序要执行的第一个指令，应该存放在0号主存地址的存储单元中，所以在程序运行之前，PC会执行0号主存地址，那么，计算机的工作流程就由此开始：

0. 程序运行前，PC指向第一条指令的存储地址，也就是0号主存地址
1. PC（0）存放的内容通过地址总线传送到MAR（0）中；PC中保存的地址是0，传输给MAR的地址自然也是0，也就是说**控制器向主存指明了CPU接下来要访问的是0号地址所对应的存储单元的数据**，同时控制器会通过控制总线通知主存储器本次的操作类型
2. 主存储器根据MAR记录的地址信息，到存储体中找到0号地址所对应的数据，并将数据放到MDR中；此时，MDR中存放的数据就是要读取的第一条指令
3. CPU通过数据总线读取MDR中存放的指令，并将指令存放到控制器的IR中
4. IR保存的指令的控制码会被发送到CU，由CU分析操作码后得出“*取数*”指令；取数指令的本质，就是取出指令中的地址码所对应的主存地址的存储单元数据，并将其存放到运算器的ACC中
5. IR保存的指令的地址码（5）会被发送到MAR，主存储器会根据MAR（5）中存放的地址码到存储体中找到相应的存储单元，并将其放在MDR（2）中
6. 在控制器的指挥下MDR的数据会被传输到运算器的ACC中；到此为止，已经完成了取数的指令，现在`a=2`这个变量值也被放在ACC中


7. 控制器的PC具备自动+1的特性，所以，在上一条取数指令执行完成后，PC自加，主存地址就指向了1号地址
8. 1号地址的取值过程与0号地址的取值过程相似，1号地址对应的存储单元被加载到IR后，CU分析指令操作码后得出“*乘法*”指令，通过地址码取出变量`b=2`并存放到运算器的MQ中，此时ACC也会将变量`a=2`先存放到通用寄存器X中；也就是说，当CPU要执行乘法操作时，被乘数将存放到X中，乘数存放在MQ中
9. CU通过控制总线操作ALU执行`a*b`乘法运算，ALU对`a`和`b`变量执行乘法运算后所得的结果，会存放在ACC（6）中；`a`和`b`变量值本身较小，如果操作数的值较大，导致乘积太大时，ACC可能存不下乘积，此时则需要MQ辅助存储乘法运算结果的低位


10. 上一指令取指后PC=2，指令执行后，ACC=6
11. 取数过程仍然一致，CU通过分析指令的操作码得出“*加法*”指令，再通过地址码找到`c=1`变量的值，并将其加载到X（1）中；执行加法操作时，ACC会先存入被加数，X会存放加数
12. CU通过控制总线操作ALU执行`(a*b)+c`加法运算，并将加法运算的结果再次存放到ACC（7）中


13. 上一指令取指后PC=3，指令执行后，ACC=7
14. CPU取数后，CU分析指令的操作码得出“*存数*”指令，IR将地址码传输到MAR（8），ACC保存的值通过数据总线传输到MDR（7），通过CU会通知主存储器此次执行写入操作，最终由主存储器将数据写入存储体

[![计算机工作流程03](https://s1.ax1x.com/2022/11/25/zYUbwV.png)](https://imgse.com/i/zYUbwV)

15. 上一指令取指后PC=4
16. CPU取数，CU分析指令操作码得出“*停机*”指令，读取到停机指令时就代表着程序结束；要停止一个进程的运行需要通过系统调用或中断机制来终止该进程，所以接下来要执行的指令不属于该程序的指令，而是操作系统相关指令

### 1.2.3 计算机系统的多级层次结构

在计算机工作流程中，用高级语言编写的代码最终需要翻译成机器语言才能被CPU执行，所以，传统意义上的机器只能识别机器语言，也就是用二进制来表述的指令。CPU执行这些二进制指令的时候，还需要将其细分为更多小步骤来执行，这些小步骤也被称为*微指令*。例如*取数、乘法、加法*等指令都被划分为多个步骤执行

[![计算机系统的层次结构](https://s1.ax1x.com/2022/11/27/zUJsYD.png)](https://imgse.com/i/zUJsYD)

- 高级语言机器M3：与汇编语言一样，对程序员来说就像是能够直接识别高级语言，但事实上高级语言的代码都需要经过编译程序翻译成汇编语言，再由汇编语言程序翻译成机器语言程序。另一方面，高级语言程序难免会用到操作系统所提供的一些系统调用
- 汇编语言机器M2：对于程序员来说，就像是一台能够直接识别汇编语言的机器，但任何机器都不可能直接识别汇编语言，汇编语言代码必须经过汇编程序翻译成机器语言后才能够执行。实际上每一条汇编语言与机器语言都是一一对应的，使用汇编语言编写的程序只是更便于人类理解而已，但本质上与机器语言的指令没有太大区别，所以汇编语言依然属于低级语言，用汇编语言编程仍不方便
- 操作系统机器M2：向上提供“广义指令”（系统调用）
- 传统机器M1：识别二进制指令
- 微程序机器M0：对上层传统机器指令的分解，用微指令来解释和执行传统机器的每一条指令

对于计算机系统的5个层次结构而言，*每一个下层都是上层的基础，上层是下层的扩展*

#### 三种级别的语言

- 高级语言：C/C++、Java，高级语言程序需要通过编译器翻译成汇编语言程序
- 汇编语言：本质上就是一些*助记符*，方便人类记忆，通过汇编器翻译成机器语言
- 机器语言：二进制代码，能够被CPU执行的程序

高级语言需要通过编译、汇编后才能够得到可执行的程序，也有一些高级语言经过编译器能够直接翻译成机器语言。另外，还有一些高级语言代码的执行并不通过编译器，而是通过解释器翻译成机器语言；这两种翻译方式也将高级语言划分为编译性语言和解释型语言

编译器：将高级语言代码全部一次性翻译成机器语言程序，再执行机器语言程序。这种方式只需要将高级语言翻译一次，以C语言程序代码为例，经过编译、汇编后会形成`.exe`文件，以后再使用该程序代码只需要执行`.exe`程序即可

解释器：将源程序的一条语句翻译成对应机器语言的语句，并立即执行，紧接着翻译下一句。每次执行该源程序都要重新翻译

## 1.3 计算机的性能指标