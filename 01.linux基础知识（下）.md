# 磁盘文件系统简述

## 文件属主与属组

`nobody`：`uid`为`99`的特殊用户

Ubuntu系统将`nobody`用户的`uid`设置为`65534`

### 文件索引属性信息-inode

`inode`：类似书目录，主要作用是指向数据真实存储在磁盘的位置；`inode`本身会存储文件属性信息、指针信息，需要注意的是，文件名称存储在上一级目录的`block`中，而非`inode`保存

`block`：用于存储真实的文件数据信息

每创建一个文件至少会占用一个`inode`和一个`block`，在同一个分区中，如果两个`inode`号相同，则两个文件互为硬链接；`block`默认大小是`4k`，文件较大时会占用多个`block`，文件较小时剩余空间无法使用，且每多占用一个block等同于多一次I/O，所以`block`的大小调整会涉及到2个方面的问题：磁盘I/O压力 和 磁盘利用率

#### 关于inode补充

文件系统大致由3个材料组成：

1. superblock：记录filesystem的整体信息，包括inode/block的总量、使用量、剩余量，及文件系统的格式与相关信息等；
2. inode：记录文件属性，一个文件占用一个inode，同时记录文件所在block的号码
3. block：实际记录文件的内容

通过inode找到block的读写方式被称为“索引式文件系统（indexed allocation）”，索引式文件系统能够通过inode记录的信息一开始就读取所有block，与之相对比的另一种文件系统FAT，FAT没有inode存在，所以无法做到批量读取block信息，FAT读取文件信息时，只能通过读取第一个block来获取下一个block的位置

原则上来说，block在格式化完后就无法再更改，除非重新格式化；EXT2每个inode大小都固定为128 bytes，EXT4和xfs可设置为256 bytes

**inode与block的大小对应关系：**

inode要记录的信息非常多，但又只有128 bytes，如果block数量巨大，inode会完全不够用，为了防止此类情况出现，系统定义了12个直接、1个间接、1个双间接、1个三间接区域用于inode记录block号码

- 直接区域：inode直接记录block号码
- 间接区域：inode指向某一个下级block，在此下级block上记录其他block的号码
- 双间接区域：在间接区域的概念基础上，双间接区域可以获取到 下下级block 用于记录其他block的号码
- 三间接区域：同上

##### Superblock

Superblock非常重要，文件系统的基本信息都写在这里，superblock的大小一般为1024 bytes，一个文件系统应该仅有一个superblock，如果出现多个superblock，那可能是对第一个block group的superblock的备份

```shell
dumpe2fs /dev/vda     # 查看EXT文件系统的superblock信息
```

使用`dumpe2fs`命令查看Superblock信息时会发现有一些`Group0`、`Group1`的字眼，正如前面所述，文件系统一开始就将inode与block规划好了，除非重新格式化或利用`resize2fs`等命令调整文件系统大小，否则inode与block固定后不再更改。但如果文件系统容量高达数百GB时，那么将所有inode与block放置在一起将会增加管理的复杂性，因此EXT文件系统在格式化时就区分为多个`block group`，每个`block group`都有独立的inode/block/superblock系统

### 用户访问文件步骤

1. 用户访问文件 `test.txt`，通过路径名获取`inode`位置
2. 从`inode`中获取文件属性信息（权限）和指针信息
3. 鉴权通过后通过指针找到`block`获取数据信息

### 文件删除原理

#### 硬链接与cp命令备份的区别

硬链接备份时，数据未增加，只是查看数据的入口增加；所以硬链接只能解决误删除的问题，不能解决误修改问题，文件修改后所有硬链接都指向同一个文件，都会一起修改

cp命令备份时，数据增加备份了一份，会占用更多的磁盘空间；cp命令能解决硬链接的问题

只能对文件做硬链接，不能对目录做硬链接：每一个目录都是一个挂载点，在挂载的规则中，每一个挂载点与一个设备是一一对应的，如果能够对目录做硬链接，那等同于打破了挂载的规则

默认新建普通文件硬链接数是1，默认新建目录硬链接数是2

```shell
ll -id ~/ ~/.
```

默认目录本身是1个链接，目录下的`.`代表自身，是第2个链接，往下在该目录下每新建一个子目录，都会为该目录新添一个硬链接，例如`~/hebor/..`，`..`表示上一目录

示例：找出硬链接的所有对应文件

```shell
find / -type f -inum "699"
```

#### 导致磁盘空间不足的情况

- 第一种原因：inode序号被占满

  创建出大量小文件，会严重占用inode数量，即便此时使用df -h查看磁盘空间仍有剩余，也无法再创建新文件；文件存储分为inode和block，两者任意一个被占满都无法创建新文件，可通过df指令查看两者占用率

- 第二种原因：block空间被占满

- 第三种原因：文件被程序调用

删除一个文件必须满足3个条件：

1. 所有的硬链接都被删除

2. 文件不被任何进程调用

3. 保存该文件的block被新数据覆盖

如果某文件的所有硬链接被删除，但该文件仍被进程服务调用时，系统判定不会将新数据覆盖该文件所占用的block，换言之，在系统中查看该文件已被删除，但block仍存有数据；将调用该文件的进程服务停掉即可

##### df指令

```shell
df -i   # 查看inode占用
df -h   # 查看磁盘空间占用
```

##### lsof指令(list system open file)

查看系统打开的文件

```shell
lsof | grep delete   # 查看系统删除的文件

# 示例：以secure日志展示文件删除的原理
# 默认删除secure日志后，重启rsyslog日志服务，并重新登录几次，rsyslog服务会自动创建secure日志文件
rm /var/log/secure -f   # 删除secure日志文件
lsof | grep delete
rsyslogd 14430         root  20w   REG       253,1   2012   393798 /var/log/secure (**delete**d)
in:imjour 14430 14432      root  20w   REG       253,1   2012   393798 /var/log/secure (**delete**d)
rs:main  14430 14433      root  20w   REG       253,1   2012   393798 /var/log/secure (**delete**d)
   # 可以看到secure日志文件的inode号 393798，通过inode可以再将secure日志还原：新建一个secure文件并设置其inode号为393798
   # 如果重启rsyslog服务后，secure就会被完全删除
```

## 正则表达式

### 系统符号概念

- 通配符号（用于查找文件信息）：`*`、`{}`
- 正则符号（grep、sed、awk）
  1. 可以处理1文件中的数据信息
  2. 基础正则符号 basic regular expression（BRE）
  3. 扩展正则符号 extended regular expression（ERE）

### 系统中的普通符号

1. 美元符号：$

2. 井号符号：#

3. 叹号符号：! 

   其中一个作用是取反，在大部分地方都可以尝试通用

   ```shell
   find /dev/ -type f ! -name "*.txt"
   ```

4. 竖线符号：|

   竖线符号常与xargs命令连用，xargs命令表示将多个内容整合成一行显示

   ```shell
   xargs < passwd     # 语法与tr命令相似
        # -n：分组显示，不加参数或不使用此选项都会整合成1行显示
   xargs -n2 < passwd     # 以2行内容为1组显示，简而言之就是将原文档的每2行信息整合成1行显示
   
   find ${pwd} -type f -name "*.txt" | xargs rm     # 删除通过find命令查找的文件
        # 此命令中，如果不使用xargs而是直接rm，那么rm命令不会生效
        # xargs命令不识别别名信息，所以rm指令不需要带参数f
   
   find ${pwd} -type f -name "*.txt" -exec rm -f {} \;    # 实现与上例一样的效果
   find ${pwd} -type f -name "*.txt" -delete    # 使用find本身的选项删除查找结果
   ```

#### xargs指令

一般情况下xargs指令会配合管道符使用，xargs指令会将前一条指令的结果放在后一条指令的尾部位置，例如：

```shell
find /home/hebor/ -type f -name "*.txt" | xargs cp -a /backup/    # 本条命令的本意是将find查找的结果备份到/backup/目录中，但后半条指令实际的执行效果如下
    [xargs] cp -a /backup/ FileName1.txt FileName2.txt    # 以2个文件简单示例，可以看出xargs将查找的结果放到cp指令的尾部后，cp指令的意义就被改变了

find /home/hebor/ -type f -name "*.txt" | xargs -i cp -a {} /backup/    # 通过-i选项替换上一指令结果的位置，实现备份
    # -i：--replease=[R]，i选项默认使用{}作为find指令的结果集

find /home/hebor/ -type f -name "*.txt" | xargs --replace=R cp -a R /backup/    # 实现同样的效果，R类似变量名，可替换
    # 类似于将find查找的结果赋值给R，然后通过更改R的位置实现cp指令

find /home/hebor/ -type f -name "*.txt" | xargs cp -a -t /backup/    # 或者直接通过cp命令的-t选项指定目标目录
```

有时候使用`${}`或` `` `反引号引用命令结果时会莫名报错，可能是因为别名的问题，可以再使用反斜杠再试试，例如`${\which rm}`

#### 重定向符号

重定向的2种类型：标准重定向、错误重定向

```shell
ech test >> /home/hebor/log.txt 2>&1    # 错误或正确的提示信息都保存
echo test &>> /home/hebor/log.txt        # 上例的另一种写法
echo test 1>> /home/hebor/log.txt 2>> /home/hebor/error.txt        # 正确提示与错误提示分开
```

#### 路径符号

路径符号包括：`.`，`..`，`-`，`~`

主要是关于cd命令中的一个选项`-`，通过man手册查看cd命令可以看到，`-`表示系统环境变量`$OLDPWD`

### 通配符 & 正则符

通配符：用于匹配文件名称信息，便于快速查找文件

正则符：用于匹配文件内容信息，常被awk、sed、grep、python、java等程序或代码调用

通配符：`*`、`{}`

```shell
echo {01..100..2}        # 输出规则不连续序列，以2为间隔
echo {a,b}{c,d}        # 输出组合序列
echo A{,B}    # 特殊组合序列，输出结果为A和AB，等同于连续输出原文件和组合文件
```

正则符：用于查找文件中的文本内容

符号分类：

1. 基础正则表达式 BRE：grep、sed、awk
2. 扩展正则表达式 ERE：grep -E/egrep、sed -r、awk

正则符号使用注意事项：

1. 以行信息进行过滤处理 sed、awk
2. 正则表达式符号禁止中文

#### 基础正则符号说明

基础正则符号包括：`^`、`$`、`.`、`*`、`[]`、`[^]`、`\`

示例：创建实验环境

```
I am oldboy teacher!
I teach linux.

I like badminton ball ,billiard ball and chinese chess!
my blog is http://oldboy.blog.51cto.com
our site is http://www.etiantian.org
my qq num is 49000448

not 4900000448
my god ,i am not oldbey,but OLDBOY!
```

示例：基础正则表达式符号解析

```shell
# ^：表示以某字符开头
grep "^m" test.txt    # 过滤测试文件中以m开头的内容

# $：表示以某字符结尾
grep "m$" test.txt    # 过滤测试文件中以m结尾的内容
grep "^$" test.txt    # 过滤文件空行信息

# .：表示任意一个字符；*：表示任意数量的前一个字符
grep "^m.*m$" test.txt    # 过滤以m开头并以m结尾的行；.和*联合使用表示匹配所有内容
grep "90*" test.txt    # 过滤文本中包含多个或0个 0字符 的行
    # 关于*的使用需要特别注意2点：过滤前一个字符、出现0次或多次
    # 如果将此示例中的条件从 "90*" 改为 "0*"，那么grep会将整个测试文件的文本都匹配，因为0字符出现0次的行被匹配
    # 通过grep指令的-o选项可以查看条件为"90*"时，grep匹配的结果分为2种：9 或 9000，分别代表0字符出现0次与多次

# \：转义符
grep "\.$" test.txt    # 将有特殊意义的符号转义为普通字符
echo -e "first paragrpph\nsecond paragraph"    # 换行符
    \n：换行
	\t：制表

# []：表示单独匹配括号中的每一个字符；[^ ]：表示对中括号中匹配的内容取反
grep "[ol]" test.txt    # 匹配o字符或l字符的行，"[]"括号中的每一个字符都是逻辑或关系
grep -E "o|l" test.txt    # 实现与上例一样的效果
grep -n "[0-9]" test.txt    # 匹配所有数字，显示行号。括号中的数字也可替换成字符a-z，表示匹配所有字符
    -i：忽略大小写
    -n：显示行号
    -E：支持扩展正则
    -v：反选
grep -Ev "^#|^$" test.txt    # 排除空行和注释

# 示例：过滤以m或I开头的行
grep "^[mI]" test.txt
sed -n "/^[mI]/p" test.txt
awk "/^[mI]/" test.txt
```

> **补充：正则符号特性**

正则符号匹配字符信息时，拥有贪婪特性。例如，本意通过如下指令截取测试文本中的字符串"I like badminton b"时

```shell
grep "^I l.*b" test.txt    # 贪婪特性会持续匹配以b结尾的单词，直到本行文本中的最后一个b字符
	# 此处实际匹配出的内容是"I like badminton ball ,billiard b"
    # 为了更精准的匹配，匹配条件应该尽可能的具备唯一性
grep "^I l.*n b" test.txt    # 避免贪婪属性
```

> **补充：grep的过滤规则**

grep以行信息过滤，通过`-o`选项可以查看grep过滤时，是匹配的文本行内容中的哪一个字符

```shell
grep "." test.txt -o        #  使用 . 过滤时，每一行的每一个字符都会被匹配
grep "^m" test.txt -o    # 与上例对比
```

> **补充：检查文件尾部的空格**

通常文本开头是否有空格很好判断，但尾部不便查看，有2种方式显示尾部结尾信息

1. 通过底行命令模式设置`set list`
2. 通过cat指令的-A选项查看`cat -A filename`

#### 扩展正则符号说明

扩展正则符包括：`+`、`|`、`()`、`{}`、`?`

示例：新建测试文件

```
zhao  110105199003065412
qian  120107198006077652
sun   310107198006077652
li    120109198006077652
zhou  897107198006077652
feng  text
wu    12010719800607765X
chu   content
zheng 311007198006077652
wang  120107198006077652
```

示例：扩展正则表达式符号解析

```shell
# +：表示前一个字符出现1次或以上。与*的区别就在于+号不匹配0次
egrep "0+" test.txt    # 匹配0字符出现1次以上的行
egrep "[0-9]+" id.txt -o    # 匹配数字出现多次的行。此处-o会将行信息作为整体输出，因为"[0-9]+"会匹配整行内容的所有数字
grep "[0-9]" id.txt -o    # 与上例对比
    # 扩展正则符+会常与[]符配合使用，用于匹配多个不同的连续字符

# |：表示匹配多个信息时作为逻辑或运算
egrep "oldboy|oldbey" test.txt    # 可以连续多次进行|匹配
sed -rn "/oldboy|oldbey/p" test.txt    # -r选项识别扩展正则符
awk "/oldboy|oldbey/" test.txt

# ()：表示将匹配的信息作为一个整体进行查询。与[]符对比，()符针对括号内的字符串不再拆分匹配每一个单独的字符，而是字符串整体匹配
egrep "(oldboy)" test.txt    # 过滤oldboy字符串

# {}：指定前一个字符连续匹配次数。{n,m}是标准语法，匹配n~m次；四种用法：{n,m}、{n}、{n,}、{,m}
egrep "0{1,3}" test.txt    # 过滤0字符出现1~3次的行，在本例中也限制了匹配次数，一行中出现多个0时最多只匹配3个0，多余的字符换行匹配
egrep "0+" test.txt    # 结果上来看与上例并无区别，可以通过-o选项查看区别
egrep "0{3}" test.txt    # 只匹配0字符连续出现n次的行

# ?：表示匹配前一个字符出现0次或1次
egrep "0?" test.txt -o
```

> **补充：关于()符在sed命令中的特殊作用**

在sed命令中()符用于后项引用前项。sed命令替换信息操作中，将不变的信息用()符声明

```shell
echo 123456 | sed "s#123456#<123456>#g"		# 想实现的效果
echo 123456 | sed "s#......#<123456>#g"		# 首次优化。将数字用6个 . 符号替代
echo 123456 | sed "s#.*#<123456>#g"		# 二次优化。将6个 . 符号用基础正则符优化
echo 123456 | sed -r "s#(.*)#<\1>#g"	# 优化结果。(.*)表示将6个数字视做一个整体（前项），"\1"表示前项，在"\1"两侧加上"<>"号等同于在前项两侧加上尖括号
echo 123456 | sed -r "s#(..)(..)(..)#<\1><\2><\3>#g"	# 将前项分开处理。后项的数字分别代表前项的第几个括号内容
echo 123456 | sed -r "s#(.{2})#<\1>#g"  # 上例简化
```

#### 正则符使用误区

以`^`符和`*`符的区别为例，辨别以下两个示例的区别

```shell
find /etc/ -type f -name "network*"    # 通配符。根据文件名称查找文件
find /etc/ -type f -name "^network"    # 正则符。根据文件内容过滤信息
```

两个示例乍一看似乎是一个意思，此处就容易涉及到通配符和正则符的误区。再次重申：通配符用于匹配文件名称信息，便于快速查找文件；正则符用于匹配文件内容信息，常被awk、sed、grep、python、java等程序或代码调用

#### 正则表达式实践

```shell
# 获取IP的3种方式：sed、awk、grep
# 1. 定位信息所在行
ip address show eth0 | sed -n "3p"
ip address show eth0 | awk 'NR==3'    # NR表示Number Row；一个=号是赋值，必须使用==号
ip address show eth0 | grep "inet "    # inet后面的空格必须有，否则会过滤出ipv6信息

# 2. 截取指定信息
ip add show eth0 | sed -n "3p" | sed -r "s#(.*inet )([0-9.]*)(/.*)#\2#g"    # sed 实现需求，此例中也可以只声明一个前项
ip add show eth0 | sed -n "3p" | sed -r "s#.*inet |/.*##g"    # 二次精简
ip add show eth0 | sed -nr '3s#.*inet |/.*##gp'    # sed 优化结果

ip add show eth0 | awk "NR==3" | awk '{print $2}'    # awk实现需求，默认awk截取列信息时按空格截取
ip add show eth0 | awk "NR==3" | awk -F "[ /]" '{print $6}'    # 使用-F选项配合ERE将/符也视作awk的分隔符
ip add show eth0 | awk -F "[ /]+" 'NR==3 {print $3}'    # awk 优化结果
    # awk截取信息时，默认没有使用-F指定分隔符信息时，采用空格切分列，但是一行字符开头的多个空格会忽略不记

ip add show eth0 | grep "inet " | egrep "[0-9\.]+" -o | head -n 1    # 巧妙的应用-o选项输出IP
    # 关于"[0-9\.]"在此处属于取巧了，匹配IP严格意义上的写法应该是"[0-9]+\.[0-9]\.[0-9]\.[0-9]+"或"([0-9]+\.){3}[0-9]+"
    # grep 优化结果 "([0-9]+\.?){4}"

# 获取文件权限信息：sed、awk
stat /etc/hosts | sed -n '4p' | sed -r 's#.*s: \(|/-.*##g'

stat /etc/hosts | awk 'NR==4' | awk -F "[ (/]" '{print $3}'    # 实现需求
stat /etc/hosts | awk -F "[(/]" 'NR==4 {print $2}'    # awk 优化

stat -c %a /etc/hosts    # 直接通过命令获取权限
```

sed擅长取行、替换修改文件信息，awk擅长取列、数据统计

> **获取信息的第4种方式（思路）**

在linux系统中，是否存在一些命令能够更加简单直接的获取到想要的信息，例如获取IP。有些重要的系统信息，会有相应的命令或参数直接显示

```shell
hostname    # 查看主机名
hostname -i    # -i选项表示获取与本机hostname对应的IP。/etc/hosts文件
hostname -I    # -I选项表示获取本机的所有IP
```

> **正则表达式补充**

```shell
[:alnum:]：代表英文字母大小写及数字
[:alpha:]：代表任何英文大小写字母
[:blank:]：代表空格和tab键
[:cntrl:]：代表键盘上的控制键
[:digit:]：代表数字
[:graph:]：除了空格和tab以外的任何键
[:lower:]：代表小写字母
[:print:]：代表任何可以打印出来的字母
[:punct:]：代表标点符号
[:upper:]：代表大写字母
[:space:]：代表任何能产生空白的字元
[:xdigit:]：代表16进制数字类型
```